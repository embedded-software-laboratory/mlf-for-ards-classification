process:
  load_models: False
  load_timeseries_data: True
  perform_anomaly_detection: True
  perform_imputation: False
  perform_unit_conversion: False
  calculate_missing_params: False
  perform_ards_onset_detection: False
  perform_filtering: False
  perform_feature_selection: False
  perform_data_segregation: False
  perform_timeseries_training: False
  perform_timeseries_classification: False
  perform_threshold_optimization: False
  calculate_evaluation_metrics: False
  perform_cross_validation: False
  save_models: False
  # Information for image models
  load_image_data: false
  train_image_models: false
  execute_image_models: false
  test_image_models: false

models:
    timeseries_models:
        to_train:
          AdaBoost:
            Names: [ "AdaBoost"]
            Configs: [ "default"]
            Active: True
          #BayesianNetwork:
          #  Names: [ ]
          #  Configs: []
          #  Active: False
          LightGBM:
            Names: [ ]
            Configs: []
            Active: False
          LogisticRegression:
            Names: [ ]
            Configs: []
            Active: False
          RandomForest:
            Names: [ "RandomForest"]
            Configs: [ "default"]
            Active: True
          SupportVectorMachine:
            Names: [ ]
            Configs: []
            Active: False
          XGBoost:
            Names: [ "XGBoost"]
            Configs: [ "default"]
            Active: True

        to_execute:
          AdaBoost:
            Names: ["AdaBoost"]
            Active: True
          #BayesianNetwork:
          #  Names: []
          #  Active: False
          LightGBM:
            Names: []
            Active: False
          LogisticRegression:
            Names: []
            Active: False
          RandomForest:
            Names: ["RandomForest"]
            Active: True
          SupportVectorMachine:
            Names: []
            Active: False
          XGBoost:
            Names: ["XGBoost"]
            Active: True

        to_evaluate:
          AdaBoost:
            Names: ["AdaBoost"]
            Active: True
          #BayesianNetwork:
          #  Names: []
          #  Active: False
          LightGBM:
            Names: []
            Active: False
          LogisticRegression:
            Names: []
            Active: False
          RandomForest:
            Names: ["RandomForest"]
            Active: True
          SupportVectorMachine:
            Names: []
            Active: False
          XGBoost:
            Names: ["XGBoost"]
            Active: True

        to_cross_validate:
          AdaBoost:
            Names: ["AdaBoost"]
            Configs: ["default"]
            Active: True
          ##BayesianNetwork:
          ##  Names: [ ]
          ##  Configs: [ ]
          #  Active: False
          LightGBM:
            Names: [ ]
            Configs: [ ]
            Active: False
          LogisticRegression:
            Names: [ ]
            Configs: [ ]
            Active: False
          RandomForest:
            Names: ["RandomForest"]
            Configs: [ "default"]
            Active: True
          SupportVectorMachine:
            Names: [ ]
            Configs: [ ]
            Active: False
          XGBoost:
            Names: ["XGBoost" ]
            Configs: ["default" ]
            Active: True
        base_path_config:
          to_train: "Data/Models/TimeSeriesModels/Config/Training/"
          to_cross_validate: "Data/Models/TimeSeriesModels/Config/CrossValidation/"

    image_models:
      to_train:
        ResNet:
          Active: False
          Configs:
          - default
          Names:
          - ResNet
        DenseNet:
          Active: False
          Configs:
          - default
          Names:
          - DenseNet
        ViT:
          Active: False
          Configs:
          - default
          Names:
          - ViT
      to_evaluate:
        ResNet:
          Active: False
          Names:
          - ResNet
        DenseNet:
          Active: False
          Names:
          - DenseNet
        ViT:
          Active: False
          Names:
          - ViT
      to_execute:
        ResNet:
          Active: False
          Names:
          - ResNet
        DenseNet:
          Active: False
          Names:
          - DenseNet
        ViT:
          Active: False
          Names:
          - ViT
      to_cross_validate:
        ResNet:
          Active: False
          Configs:
          - default
          Names:
          - ResNet
        DenseNet:
          Active: False
          Configs:
          - default
          Names:
          - DenseNet
        ViT:
          Active: False
          Configs:
          - default
          Names:
          - ViT

algorithm_base_path:
  AdaBoost: "default"
  #BayesianNet: "default"
  LightGBM: "default"
  LogisticRegression: "default"
  RandomForest: "default"
  SupportVectorMachine: "default"
  XGBoost: "default"
  RecurrentNeuralNetwork: "Save/Cross validation results/Recurrent neural network_1"

storage_path: "../Data/ExperimentResult/Seeds"

data:
  database: "UKA"
  pneumonia_image_dataset: "balanced"
  ards_image_dataset: "weighted"
  timeseries_file_path: "/work/rwth1474/Data/time_series/uka_data_050623.npy"
  import_type: numpy # Options: numpy, csv, pkl, split
  image_file_path: "Data/Image_data"

preprocessing:
  patients_per_process: 500
  max_processes: 2

  anomaly_detection:
    SW_ABSAD_MOD:
      active: False
      name: "SW_ABSAD_MOD"
      columns_to_check: []
      fix_algorithm: "interpolate"
      handling_strategy: "delete_than_impute"
      anomaly_threshold: 0.5
      supported_stages:
        - "prepare"
        - "predict"
        - "fix"
      active_stages:
        - "fix"
      anomaly_data_dir: "/work/rwth1474/Data/AnomalyDetection/anomaly_data/SW_ABSAD_MOD"
      prepared_data_dir: "/work/rwth1474/Data/AnomalyDetection/prepared_data/SW_ABSAD_MOD"
      replace_zeros: False
      replace_physical_outliers: True
      use_cl_modification: False
      retrain_after_gap: True
      window_length: 7
      variance_check: False
      clea_training: False
      variance_window: 7
      confidence_level: 0.95
      theta: 0.5
      k: 5
      s: 5
    Physiological_Outliers:
      active: False
      name: "Physiological_Outliers"
      columns_to_check: [ ]
      fix_algorithm: "forward"
      handling_strategy: "delete_than_impute"
      anomaly_threshold: 0.5
      supported_stages:
        - "prepare"
        - "predict"
        - "fix"
      active_stages:
        - "fix"
      anomaly_data_dir: "/work/rwth1474/Data/AnomalyDetection/anomaly_data/Physical_Outliers"
      prepared_data_dir: "/work/rwth1474/Data/AnomalyDetection/prepared_data/Physical_Outliers"

    DeepAnt:
      active: False
      name: "DeepAnt"
      columns_to_check: []
      fix_algorithm: "forward"
      handling_strategy: "delete_than_impute"
      anomaly_threshold: 0.5
      supported_stages:
        - "prepare"
        - "train"
        - "predict"
        - "fix"
      active_stages:
        - "fix"
      anomaly_data_dir: "/work/rwth1474/Data/AnomalyDetection/anomaly_data/DeepAnt"
      prepared_data_dir: "/work/rwth1474/Data/AnomalyDetection/prepared_data/DeepAnt"
      window_generator_config:
        input_width: 10
        output_width: 10
      val_percentage: 0.1
      train_percentage: 0.2
      sk_seed: 42
      learning_rate: 0.001
      hidden_size: 256
      max_epochs: 100
      max_initial_epochs: 10
      batch_size: 32
      patience: 5
      run_dir: "../Data/Models/AnomalyDetection/DeepAnt"
      checkpoint_dir: "../Data/Models/AnomalyDetection/DeepAnt/checkpoints"

      load_data: True
      save_data: True
      retrain_models: {}

    ALAD:
      active: True
      name: "ALAD"
      columns_to_check: [ ]
      fix_algorithm: "interpolate"
      handling_strategy: "delete_than_impute"
      anomaly_threshold: 0.5
      supported_stages:
        - "prepare"
        - "train"
        - "predict"
        - "fix"
      active_stages:
        - "prepare"
        - "train"
        - "predict"
        - "fix"
      anomaly_data_dir: "/work/rwth1474/Data/AnomalyDetection/anomaly_data/ALAD"
      prepared_data_dir: "/work/rwth1474/Data/AnomalyDetection/prepared_data/ALAD"

      train_percentage: 0.2
      sk_seed: 42
      hyperparameters: {}
      run_dir: "../Data/Models/AnomalyDetection/DeepAnt"
      checkpoint_dir: "../Data/Models/AnomalyDetection/DeepAnt/checkpoints"

      load_data: True
      save_data: True
      retrain_models: { }

  filtering:
    filter:
    - BD
    - Strict

  imputation: 
    impute_empty_cells: True
    default_imputation_method: "forward"
    params_to_impute:
      - ards, forward
      - all

  params_to_calculate:
    - horovitz
  ards_onset_detection:
    detection_rule: "first_horovitz"
    #eventuell ver√§ndern.. bsp. lowest horowitz
    return_rule: "datapoint" 
    series_start_point: -50000
    series_end_point: 50000
    remove_ards_patients_without_onset: False
    impute_missing_rows: False
    update_ards_values: False

feature_selection:
  method: "univariate"
  variance: 0.16
  k: 15
  neighbor: 5 # neighbor parameter for relief algorithm (default is 5)

data_segregation:
  training_test_ratio: 0.8
  percentage_of_ards_patients: 0.1
  splitting_seed: 42

evaluation:
  cross_validation:
    n_splits: 5
    shuffle: True
    random_state: 42
  threshold_optimization_algorithms: ["Standard", "MaxTPR", "MaxTPRMinFPR", "GeometricRoot"]
  evaluation_metrics: ["AUC", "Accuracy", "F1Score", "FPR", "MCC", "OptimalProbability", "Sensitivity", "Specificity", "TPR","PPV", "NPV", "Precisions", "Recalls"]
  evaluation_name: "Evaluation ALAD Test"

image_model_parameters:
  # defines the method for fine-tuning for the dl models
  # Options: last_layer, last_block, model
  method: last_block
  
  # Data augmentation modes (controls which datasets use augmented data)
  # mode1: No augmentation - standard training with original images
  # mode2: Reserved for future use (augmentation during training only via transforms)
  # mode3: ARDS training data uses pre-augmented dataset (MIMIC-DB-AUG folder)
  # mode4: ARDS training AND test data use pre-augmented datasets
  # Note: PNEUMONIA training always uses non-augmented data (CheXpert-DB-PNEUMONIA)
  mode: mode1
  
  # =========================
  # CNN Models (ResNet, DenseNet)
  # =========================
  # Pretraining parameters
  learning_rate_pre_cnn: 0.001
  batch_size_pre_cnn: 64
  weight_decay_pre_cnn: 0.00001
  
  # Main training parameters
  learning_rate_cnn: 0.05
  epoch_decay_cnn: 0.002 
  weight_decay_cnn: 0.00001
  margin_cnn: 1.0
  
  # Pneumonia pretraining stage
  num_epochs_pneumonia: 1
  batch_size_pneumonia: 32
  SEED_pneumonia: 123
  
  # ARDS fine-tuning stage
  num_epochs_ards: 1
  batch_size_ards: 32
  SEED_ards: 105
  
  # Cross-validation
  k_folds: 2  # Use 1 for simple 80/20 split (faster), 2+ for k-fold cross-validation
  
  # =========================
  # ViT Models (Vision Transformer)
  # =========================
  learning_rate_vit: 0.0005
  batch_size_vit: 32
  k_folds_vit: 2

supported_algorithms:
  timeseries_models:
    - AdaBoostModel
    #- BayesianNetworkModel
    - LightGBMModel
    - LogisticRegressionModel
    - RandomForestModel
    - SupportVectorMachineModel
    - XGBoostModel
  image_models:
    - ResNetModel
    - DenseNetModel
    - ViTModel
